
# Variational Auto Encoder Project

## Description

This project focuses on implementing a Variational Autoencoder (VAE) using Python, with a specific emphasis on two main objectives:

1. **Section 1**: Implementation of an LSTM text generator. The model is trained on the Enron corpus or a text source of your choice.
2. **Section 2**: Implementation of a variational autoencoder using the MNIST dataset. The project involves saving a grid of 15 x 15 digits to the `results/vae` directory.

## Features

- **LSTM Text Generator**: Explore the capabilities of LSTM networks in generating text.
- **Variational Autoencoder**: Understand and implement VAEs, specifically applied to the MNIST dataset.
- **Image Generation**: Learn about generating and visualizing data in the form of a grid of digits.

## Installation

Refer to the `requirements.txt` file for dependency details. Use the following commands to set up your environment:

```bash
# Install dependencies
pip install -r requirements.txt
```

## Usage

See the provided examples in the notebook for guidance on how to utilize the VAE model and the LSTM text generator in your projects.

## Contributing

Contributions to this project are welcome! Follow the standard GitHub workflow: fork the repository, create a feature branch, commit your changes, push to the branch, and open a pull request.

## License

This project is released under the MIT License.
